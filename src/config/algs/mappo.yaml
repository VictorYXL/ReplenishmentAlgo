# --- CENTRALV specific parameters ---
# Independent PPO with value norm, layer_norm, orthogonal, value clip
# but, without death agent mask, data chunk

env_args:
  key: "replenishment_efficient_env-v0"
  # map_name: "n50c1000d21s*l50"
  map_name: "n58c5000d21s_l100"
  # map_name: "n58c5000d21s0l300"
  # map_name: "n58c5000d21s0l300"
  # map_name: "n58c20000d21s*l100"
  # time_limit: 50
  time_limit: 100
test_interval: 8000
log_interval: 8000
runner_log_interval: 8000
learner_log_interval: 8000

action_selector: "multinomial"
epsilon_start: .0
epsilon_finish: .0
epsilon_anneal_time: 100000
mask_before_softmax: True

runner: "parallel"
use_individual_rewards: False
use_mean_team_reward: False
buffer_size: 8
batch_size_run: 8
batch_size: 8
# accumulated_episodes: 8

mac: 'mappo_mac'
agent: 'n_rnn'
# agent: 'mlp'
actor_input_seq_str: 'o_la'

lr: 0.0005
critic_coef: 0.5
entropy_coef: 0.01
gae_lambda: 0.95
mini_epochs: 4
eps_clip: 0.2
save_probs: True

agent_output_type: "pi_logits"
learner: "ppo_learner"
critic_type: "mappo_rnn_critic" 
# critic_type: "mlp_critic"
critic_input_seq_str: 's_la'

use_layer_norm: True
use_orthogonal: True
gain: 0.01
use_value_norm: True

name: "mappo"
# wandb_project_name: "old_replenishment"
# wandb_project_name: "eff_replenishment_mappo_sync_c_20000"
# wandb_project_name: "eff_replenishment_mappo_train_300_c_5000"
# wandb_project_name: "eff_replenishment_mappo_sync_c_5000"
# wandb_project_name: "eff_replenishment_mappo_train_rand_c_20000"
# wandb_project_name: "eff_replenishment_mappo_debug"

run: "mappo_run"