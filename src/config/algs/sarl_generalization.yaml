
env_args:
  key: "replenishment_efficient_env-v0"
  map_name: "n58c1000d21s*l100"
  time_limit: 100
test_interval: 8000
log_interval: 8000
runner_log_interval: 8000
learner_log_interval: 8000

action_selector: "multinomial"
epsilon_start: .0
epsilon_finish: .0
epsilon_anneal_time: 100000
mask_before_softmax: True
visualize: False

runner: "parallel"

buffer_size: 50
batch_size_run: 50
batch_size: 50
# accumulated_episodes: 8

mac: 'mappo_mac'
agent: 'mlp'
hidden_dim: 128
actor_input_seq_str: 'o'

lr: 0.0005
critic_coef: 0.5
entropy_coef: 0.001 #0.001
reg_coef: 0.01
gamma: 0.985
gae_lambda: 0.95
mini_epochs: 4
eps_clip: 0.2
save_probs: True

agent_output_type: "pi_logits"
learner: "cdppo_learner"
critic_type: "mlp_critic"
critic_input_seq_str: 'o_d'

use_layer_norm: True
use_orthogonal: True
gain: 0.01
use_value_norm: False #True

name: "sarl_generalization"
train_with_joint_data: False
n_decoupled_iterations: 1
max_individual_envs: 10
fake_dynamics_prob: 0.15
select_ls_randomly: True
use_zero_like_context : True
aug_type: 'noise'
in_amlt: False

run: "sarl_generalization_run"